\chapter{Introduction}

\Exam{I found the introduction to the thesis to be extremely short. I would have loved to see
a little more about motivating the use of array languages, what the domain of
programs that can be expressed is and why this domain matters. Also the current
limitation of Accelerate should have been discussed in more details together with a
justification as to why the work in this thesis is necessary. In particular the need for
flattening of arrays should be clearly motivated upfront.}
A programmer wanting to take advantage of the immense processing power provided by modern parallel hardware has a common but difficult choice to make. They must decide what language to use. If they use a low-level language, it raises many questions: How time-consuming will that be? How much expert knowledge of the hardware is required?  What safety guarantees are there? Will programs be portable to the hardware that comes out next year? The answers to these questions are invariably: very, a lot, not many, and no.

Alternatively, they could use a high-level language. These are typically less time consuming to use, require less hardware specific knowledge, give greater safety guarantees, and can offer portability, provided there is a compiler for the target platform. They are, however, not often capable of generating native code with the desired performance properties.

Array languages have proven a robust compromise to this problem. They lift the level of abstraction beyond that of a low-level language, but still, most importantly, offer competitive performance. By expressing computations in terms of parallel arrays, there is a near limitless amount of parallelism available of which a sufficiently smart compiler can take advantage. Programs can be written by domain experts, as opposed to high-performance computing experts.

A leading language in this category is Accelerate. It is highly expressive and rich with features and libraries. Embedded in Haskell, it offers combinators familiar to functional programmers, enabling them to write fast programs that closely resemble conventional Haskell programs. In this dissertation, we build upon Accelerate to widen the domain of programs that can be expressed within it. Not only that but, in doing so, we produce more general results that can be applied to any array language. Primarily, a program transformation for flattening nested parallelism that identifies and tracks the shape of nested structures.

This dissertation builds on existing work on Accelerate, and also array languages generally. Both prior to and during my contribution, numerous other researchers, also made many contributions. The research to which I have contributed is listed below. I explicitly state which work is my own:

\begin{itemize}
\item We have developed a new parallel structure in addition to the parallel array. Irregular arrays sequences offer a single level of nesting with greater modularity and controlled memory usage (Chapter~\ref{chap:motivation}).
\item I developed a novel extension to Blelloch's flattening transform~\cite{Blelloch:compiling1988,Blelloch:nesl1995} that identifies regular (sub)computations and transforms them according to different rules than irregular computations. By doing this I was able to take advantage of the greater efficiency afforded by regular computations, but fall back to less efficient methods when computations are irregular (Chapter~\ref{chap:theory}).
\item I implemented a system for treating the memory on Graphics Processing Units (GPUs) as a cache for GPU computations. A programmer using Accelerate with this feature does not have to be as concerned about their programs working memory fitting into the limited memory of the GPU (Section~\ref{sec:gpu-gc}).
\item I developed an foreign function interface (FFI) for Accelerate. This was the first, to my knowledge, FFI for an embedded language. The technique for doing this applies to all deeply embedded languages with multiple execution backends. In Accelerate, it allows for highly optimised low-level libraries to be called from within a high-level Accelerate program and for Accelerate programs to be called from CUDA C programs (Section~\ref{sec:foreign}).
\end{itemize}

Before describing any of this work, however, we first introduce the background and context of our research in Chapter~\ref{chap:background}.
