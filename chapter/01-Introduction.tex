\chapter{Introduction}

A programmer wanting to take advantage the immense processing power provided by modern parallel hardware has a common but difficult choice to make. They must decide what language to use. If they use a low-level language, it raises a number of questions: How time consuming will that be? How much expert knowledge of the hardware is required?  What safety guarantees are there? Will programs be portable to the hardware that comes out next year? The answers to these questions are invariably: very, a lot, not many, and no.

Alternatively, they could use a high-level language. These are typically less time consuming to use, require less hardware specific knowledge, give greater safety guarantees, and can offer portability, provided there is a compiler for the target platform. They are, however, often not capable of generating native code with the desired performance properties.

Array languages have proven a robust compromise to this problem. They lift the level of abstraction beyond that of a low-level language, but still, most importantly, offer competitive performance. By expressing computations in terms of parallel arrays there is a near limitless amount of parallelism available for a sufficiently smart compiler to take advantage of. Programs can be written by domain experts, as opposed to high-performance computing experts.

A leading language in this category is Accelerate. It is highly expressive and rich with features and libraries. Embedded in Haskell, it offers combinators familiar to functional programmers, enabling them to write fast programs that closely resemble conventional Haskell programs. In this dissertation, we build upon Accelerate to widen the domain of programs that can be expressed within it. Not only that, but, in doing so, we produce more general results that can be applied to any array language. Primarily, a program transformation for flattening nested parallelism that identifies and tracks the shape of nested structures.

This dissertation builds on existing work on Accelerate, and also array languages generally. Both prior to and during my contribution, numerous other researchers also made many contributions. The research to which I have contributed is listed below. I explicitly state which work is my own:

\begin{itemize}
\item We have developed a new parallel structure in addition to the parallel array. Irregular arrays sequences offer a single level of nesting with greater modularity and controlled memory usage (Chapter~\ref{chap:motivation}).
\item I developed a novel extension to Blelloch's flattening transform~\cite{Blelloch:compiling1988,Blelloch:nesl1995} that identifies regular (sub)computations and transforms them according to different rules than irregular computations. By doing this I was able to take advantage of the greater efficiency afforded by regular computations, but fall back to less efficient methods when computations are irregular (Chapter~\ref{chap:theory}).
\item I implemented a system for treating GPU memory as a cache for GPU computations. A programmer using Accelerate with this feature does not have to be as concerned about their programs working memory fitting into the, limited, memory of the GPU (Section~\ref{sec:gpu-gc}.
\item I developed an FFI for Accelerate. This was the first, to my knowledge, FFI for an embedded language. The technique for doing this is applicable to all embedded languages with multiple execution backends. In Accelerate, it allows for highly optimised low-level libraries to be called from within a high-level Accelerate program and for Accelerate programs to be called from CUDA C programs (Section~\ref{sec:foreign}).
\end{itemize}

Before describing any of this work, however, we first introduce the background and context of our research in Chapter~\ref{chap:background}.
